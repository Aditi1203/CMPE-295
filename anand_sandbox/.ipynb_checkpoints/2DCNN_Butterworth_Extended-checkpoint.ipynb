{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-83358da30272>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-83358da30272>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip3 install pandas\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-131d73e6b5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "from keras.applications import VGG19, VGG16\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import Sequential, losses, optimizers, Input\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Average, Flatten, Dropout, Activation\n",
    "from keras.utils import to_categorical, plot_model,vis_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from skimage import io\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import pywt\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModel:\n",
    "    \"\"\"\n",
    "            DataModel\n",
    "            not used currently in the program.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.items_labels = None\n",
    "        self.images = []\n",
    "        self.curated_data = {}\n",
    "    def add_image(self, image_array):\n",
    "        self.images.append(image_array)\n",
    "    def add_labels(self, df):\n",
    "        self.item_labels = df\n",
    "    def add_curated_data(self, image, emotion):\n",
    "        self.curated_data['segment'] = image #Array from csv of each segment\n",
    "        self.curated_data['label'] = label #Label\n",
    "        self.curated_data['scalogram'] =scaledImage #scalogram of each segment\n",
    "\n",
    "def load_data(number_of_items=90):\n",
    "    \"\"\"\n",
    "        number_of_items -> Number of items to return\n",
    "        returns the data in a dictionary of images and labels.\n",
    "    \"\"\"\n",
    "    path = \"butterworth_kalman_result_Scalogram\"\n",
    "    path1= \"butterworth_kalman_result_Scalogram/Cropped\"\n",
    "    data = [] \n",
    "    curated_data = {\"label\":[], \"scalogram\":[]}\n",
    "    for subject_name in os.listdir(path)[:number_of_items]:\n",
    "        # At the start of the iteration build a data model\n",
    "        data_model = DataModel()\n",
    "        if subject_name == \".DS_Store\":\n",
    "            continue\n",
    "        if subject_name  ==\".ipynb_checkpoints\":\n",
    "            continue\n",
    "        if subject_name  ==\".svn\":\n",
    "            continue\n",
    "        print (\"Going through subject:\" + subject_name)\n",
    "        base=os.path.basename(path+\"/\"+subject_name)\n",
    "        labelData=os.path.splitext(base)[0]\n",
    "        print(labelData)\n",
    "        i=0\n",
    "        for items in os.listdir(path+\"/\"+subject_name):\n",
    "            if items == \".DS_Store\":\n",
    "                continue\n",
    "            if items.endswith(\".png\"):\n",
    "                #i=i+1\n",
    "                #print(i)\n",
    "                try:\n",
    "                    im2 = cv2.imread(path+\"/\"+subject_name+\"/\"+items)\n",
    "                    #plt.imshow(im2)\n",
    "                    #plt.show()\n",
    "                    crop_img = im2[30:20+235, 50:50+342]\n",
    "                    im = cv2.resize(crop_img, (224,224)) # Changing into 80x80X3\n",
    "                    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "                    #print(type(crop_img))\n",
    "                    #plt.imshow(crop_img)\n",
    "                    #plt.show()\n",
    "                    \n",
    "\n",
    "              #curated_data['segments'].append(df1)\n",
    "                    #curated_data['scalogram'].append(crop_img)\n",
    "                    curated_data['scalogram'].append(im)\n",
    "                    curated_data['label'].append(labelData)\n",
    "              #print(df1)\n",
    "                except:\n",
    "                      df = None  \n",
    "        #data.append(data_model) # Save all the data\n",
    "\n",
    "    return curated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(number_of_items=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=np.array(data['scalogram'])\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = encoder.transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_classes = encoder.classes_\n",
    "mapping = {0: 'person_100',\n",
    " 1: 'person_101',\n",
    " 2: 'person_102',\n",
    " 3: 'person_103',\n",
    " 4: 'person_104',\n",
    " 5: 'person_106',\n",
    " 6: 'person_107',\n",
    " 7: 'person_108',\n",
    " 8: 'person_109',\n",
    " 9: 'person_111',\n",
    " 10: 'person_112',\n",
    " 11: 'person_113',\n",
    " 12: 'person_114',\n",
    " 13: 'person_115',\n",
    " 14: 'person_116',\n",
    " 15: 'person_117',\n",
    " 16: 'person_118',\n",
    " 17: 'person_119',\n",
    " 18: 'person_121',\n",
    " 19: 'person_122',\n",
    " 20: 'person_123',\n",
    " 21: 'person_124',\n",
    " 22: 'person_200',\n",
    " 23: 'person_202',\n",
    " 24: 'person_203',\n",
    " 25: 'person_205',\n",
    " 26: 'person_207',\n",
    " 27: 'person_208',\n",
    " 28: 'person_209',\n",
    " 29: 'person_210',\n",
    " 30: 'person_212',\n",
    " 31: 'person_213',\n",
    " 32: 'person_214',\n",
    " 33: 'person_215',\n",
    " 34: 'person_217',\n",
    " 35: 'person_219',\n",
    " 36: 'person_220',\n",
    " 37: 'person_221',\n",
    " 38: 'person_222',\n",
    " 39: 'person_223',\n",
    " 40: 'person_228',\n",
    " 41: 'person_230',\n",
    " 42: 'person_231',\n",
    " 43: 'person_232',\n",
    " 44: 'person_233',\n",
    " 45: 'person_234'    \n",
    "          }\n",
    "\n",
    "#print(mapping)\n",
    "\n",
    "\n",
    "# Get emotion from class number   \n",
    "def get_name_from_class(class_number):\n",
    "    \"\"\"\n",
    "        gets the corresponding subject from the class\n",
    "    \"\"\"\n",
    "    if mapping.get(class_number,None):\n",
    "        return mapping.get(class_number)\n",
    "    else:\n",
    "        return -1 # No such class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features and labels\n",
    "features = np.array(data['scalogram'])\n",
    "labels = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of features: \", features.shape)\n",
    "print (\"Shape of labels: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing\n",
    "labels = to_categorical(labels, num_classes=len(mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=5, input_shape=(224, 224, 1), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32, kernel_size=5, activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(150, activation=\"relu\"))\n",
    "#model.add(Dense(120, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(80, activation=\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(len(mapping), activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizers.RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard()\n",
    "earlystopping = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "features_train = features_train.astype(\"float32\")\n",
    "features_test = features_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train / 1/255\n",
    "features_test = features_test / 1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.reshape(len(features_train), 224, 224, 1)\n",
    "features_test = features_test.reshape(len(features_test), 224, 224, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model.fit(features_train, labels_train, epochs=100, batch_size=16, callbacks=[tensorboard,earlystopping], validation_data=(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"2DCNNButterworthExtended.h5\") # Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test an image\n",
    "def test_image(image,label):\n",
    "    #print(image.shape)\n",
    "    prediction = np.argmax(model.predict(image.reshape(1,224,224,1)))\n",
    "    result_predict=get_emotion_from_class(prediction)\n",
    "    actual=np.argmax(label)\n",
    "    result_actual=get_emotion_from_class(actual)\n",
    "    #print(prediction)\n",
    "    #print(actual)\n",
    "    return result_actual,result_predict\n",
    "\n",
    "    \n",
    "# Get emotion from class number   \n",
    "def get_emotion_from_class(class_number):\n",
    "    \"\"\"\n",
    "        gets the corresponding label from the class\n",
    "    \"\"\"\n",
    "    if mapping.get(class_number,None):\n",
    "      return mapping.get(class_number)\n",
    "    else:\n",
    "      return -1 # No such class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features_test)):\n",
    "    actual,predicted=test_image(features_test[i],labels_test[i])\n",
    "    print(\"Model predicts: \"+predicted+\" and actual label is: \"+actual)\n",
    "    if(predicted!=actual):\n",
    "        print(\"Wrong prediction\")\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
