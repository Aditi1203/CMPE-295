{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT_Loss_Pro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPKpaMeDePt5IZtoj2y6C45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditi1203/CMPE-295/blob/master/MIT_Loss_Without_Early_Stopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkVtdH4wdPRk",
        "colab_type": "code",
        "outputId": "85daabea-a9cc-47a1-a311-5d75151f9496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/Aditi1203/CMPE-295.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CMPE-295'...\n",
            "remote: Enumerating objects: 1152132, done.\u001b[K\n",
            "remote: Total 1152132 (delta 0), reused 0 (delta 0), pack-reused 1152132\u001b[K\n",
            "Receiving objects: 100% (1152132/1152132), 3.34 GiB | 36.46 MiB/s, done.\n",
            "Resolving deltas: 100% (220400/220400), done.\n",
            "Checking out files: 100% (738051/738051), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPU-ZJmNd1q6",
        "colab_type": "code",
        "outputId": "1dacdd2f-e4ef-4248-c619-6df926ee2686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cd CMPE-295/anand_sandbox/"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'CMPE-295/anand_sandbox/'\n",
            "/content/CMPE-295/anand_sandbox\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DNYA8d0d30G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "import random\n",
        "# from keras.applications import VGG19, VGG16\n",
        "# from keras.applications.vgg19 import preprocess_input\n",
        "# from keras.applications.vgg16 import preprocess_input\n",
        "from itertools import permutations\n",
        "from keras.optimizers import SGD,Adam\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import Sequential, losses, optimizers, Input, optimizers\n",
        "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Flatten, Lambda, Dense, Conv2D, MaxPool2D, Average, Dropout, Activation\n",
        "from keras.utils import to_categorical, plot_model,vis_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from itertools import chain \n",
        "from skimage import io\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "import pywt\n",
        "from scipy import signal\n",
        "from scipy.spatial import distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AEt03LMd61k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(number_of_items=3):\n",
        "    \"\"\"\n",
        "        number_of_items -> Number of items to return\n",
        "        returns the data in a dictionary of images and labels.\n",
        "    \"\"\"\n",
        "    path = \"scalogram_module/Scalogram\"\n",
        "    path1= \"scalogram_module/Scalogram/Cropped\"\n",
        "    data = [] \n",
        "    curated_data = {\"label\":[], \"scalogram\":[]}\n",
        "    for subject_name in os.listdir(path)[:number_of_items]:\n",
        "        if subject_name == \".DS_Store\":\n",
        "            number_of_items=number_of_items+1\n",
        "            continue\n",
        "        if subject_name  ==\".ipynb_checkpoints\":\n",
        "            number_of_items=number_of_items+1\n",
        "            continue\n",
        "        print (\"Going through subject:\" + subject_name)\n",
        "        base=os.path.basename(path+\"/\"+subject_name)\n",
        "        labelData=os.path.splitext(base)[0]\n",
        "        print(labelData)\n",
        "        i=0\n",
        "        for items in os.listdir(path+\"/\"+subject_name):\n",
        "            if items == \".DS_Store\":\n",
        "                continue\n",
        "            if items.endswith(\".png\"):\n",
        "                try:\n",
        "                    im2 = cv2.imread(path+\"/\"+subject_name+\"/\"+items)\n",
        "                    crop_img = im2[30:20+235, 50:50+342]\n",
        "                    im = cv2.resize(crop_img, (224,224)) # Changing into 80x80X3\n",
        "                    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "                    curated_data['scalogram'].append(im)\n",
        "                    curated_data['label'].append(labelData)\n",
        "                except:\n",
        "                      df = None  \n",
        "\n",
        "    return curated_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvJtEJdsd7lk",
        "colab_type": "code",
        "outputId": "21322060-5bbe-421b-b5cf-289f78a8fe11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = load_data(number_of_items=50)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Going through subject:person_207\n",
            "person_207\n",
            "Going through subject:person_111\n",
            "person_111\n",
            "Going through subject:person_228\n",
            "person_228\n",
            "Going through subject:person_223\n",
            "person_223\n",
            "Going through subject:person_213\n",
            "person_213\n",
            "Going through subject:person_214\n",
            "person_214\n",
            "Going through subject:person_109\n",
            "person_109\n",
            "Going through subject:person_212\n",
            "person_212\n",
            "Going through subject:person_208\n",
            "person_208\n",
            "Going through subject:person_202\n",
            "person_202\n",
            "Going through subject:person_219\n",
            "person_219\n",
            "Going through subject:person_230\n",
            "person_230\n",
            "Going through subject:person_100\n",
            "person_100\n",
            "Going through subject:person_106\n",
            "person_106\n",
            "Going through subject:person_102\n",
            "person_102\n",
            "Going through subject:person_123\n",
            "person_123\n",
            "Going through subject:person_118\n",
            "person_118\n",
            "Going through subject:person_103\n",
            "person_103\n",
            "Going through subject:person_222\n",
            "person_222\n",
            "Going through subject:person_232\n",
            "person_232\n",
            "Going through subject:person_221\n",
            "person_221\n",
            "Going through subject:person_209\n",
            "person_209\n",
            "Going through subject:person_201\n",
            "person_201\n",
            "Going through subject:person_220\n",
            "person_220\n",
            "Going through subject:person_205\n",
            "person_205\n",
            "Going through subject:person_124\n",
            "person_124\n",
            "Going through subject:person_200\n",
            "person_200\n",
            "Going through subject:person_117\n",
            "person_117\n",
            "Going through subject:person_104\n",
            "person_104\n",
            "Going through subject:person_113\n",
            "person_113\n",
            "Going through subject:person_107\n",
            "person_107\n",
            "Going through subject:person_122\n",
            "person_122\n",
            "Going through subject:person_210\n",
            "person_210\n",
            "Going through subject:person_233\n",
            "person_233\n",
            "Going through subject:person_114\n",
            "person_114\n",
            "Going through subject:person_116\n",
            "person_116\n",
            "Going through subject:person_101\n",
            "person_101\n",
            "Going through subject:person_121\n",
            "person_121\n",
            "Going through subject:person_234\n",
            "person_234\n",
            "Going through subject:person_105\n",
            "person_105\n",
            "Going through subject:person_231\n",
            "person_231\n",
            "Going through subject:person_115\n",
            "person_115\n",
            "Going through subject:person_217\n",
            "person_217\n",
            "Going through subject:person_119\n",
            "person_119\n",
            "Going through subject:person_203\n",
            "person_203\n",
            "Going through subject:person_215\n",
            "person_215\n",
            "Going through subject:person_112\n",
            "person_112\n",
            "Going through subject:person_108\n",
            "person_108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOEIBVpgd_Eo",
        "colab_type": "code",
        "outputId": "88695e5e-b55c-44a0-e2f5-540fa4dfc62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(data['scalogram'][0].shape)\n",
        "print(len(data['scalogram']))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224)\n",
            "50605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bojNPXYid_uI",
        "colab_type": "code",
        "outputId": "808ee161-ebd0-4f46-a865-dbe68fb5091a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data['label'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6SEMIvXeBma",
        "colab_type": "code",
        "outputId": "87737be0-c4b4-4cfe-ec50-acfc860a2e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_array=np.array(data['scalogram'])\n",
        "labels=np.array(data['label'])\n",
        "print(\"Data shape:{}\".format(data_array.shape))\n",
        "print(\"Labels shape:{}\".format(labels.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape:(50605, 224, 224)\n",
            "Labels shape:(50605,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apyktblzeD6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_array = data_array / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBjeqmf-eGQi",
        "colab_type": "code",
        "outputId": "1a3b8705-bad6-45e9-fd8c-df62fb1cd2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(labels)\n",
        "labels = encoder.transform(labels)\n",
        "print(\"Encoded Labels shape:{} value:{}\".format(labels.shape,labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded Labels shape:(50605,) value:[28 28 28 ...  8  8  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBQFrfsReGYC",
        "colab_type": "code",
        "outputId": "b1956243-9a49-4ff9-9b03-6e51c7988278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "unique_labels=set(labels)\n",
        "print(unique_labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaEPJZvneGcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train,  y_test=train_test_split(data_array, labels, test_size=0.2, random_state=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7LYZ-Te8ZwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "237d804e-85ed-4e88-fed0-6f63b958f66c"
      },
      "source": [
        "print(\"Shapes:\")\n",
        "print(\"Train Data:{}\".format(x_train.shape))\n",
        "print(\"Train Label:{}\".format(y_train.shape))\n",
        "print(\"Test Data:{}\".format(x_test.shape))\n",
        "print(\"Test Label:{}\".format(y_test.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes:\n",
            "Train Data:(40484, 224, 224)\n",
            "Train Label:(40484,)\n",
            "Test Data:(10121, 224, 224)\n",
            "Test Label:(10121,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbtW2luheMPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63bf60c8-9807-418f-c063-cbea720e5bbf"
      },
      "source": [
        "x_train_master = np.expand_dims(x_train, 3)\n",
        "x_test_master = np.expand_dims(x_test, 3)\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40484, 224, 224) (10121, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TdtdFjgeMS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fa1ef2f-6fe1-4aa5-fa53-93a7b4f53ee1"
      },
      "source": [
        "y_train_master = y_train.flatten()\n",
        "y_test_master = y_test.flatten()\n",
        "print(y_train_master.shape,y_test_master.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40484,) (10121,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uN-lHG5eMYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31fbeb60-d139-45f3-9720-9761002e264f"
      },
      "source": [
        "shape=x_train.shape\n",
        "dim_x = shape[1]\n",
        "dim_y = shape[2]\n",
        "print(\"Dimension of Scalogram Image: {}*{}\".format(dim_x,dim_y ))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of Scalogram Image: 224*224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA7iZlnheMbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_per_class = 1\n",
        "n_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qH2-0WoeMWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_triplets(dataset, label, sample_per_class=20):\n",
        "    x, y = None, None\n",
        "    for i in set(label):\n",
        "        pos_indices = np.argwhere(label == i)[:,0]\n",
        "        neg_indices = np.argwhere(label != i)[:,0]\n",
        "\n",
        "        # print(\"pos indices: {}, neg_indices: {}\".format(pos_indices.shape, neg_indices.shape))\n",
        "        choice_anchor = np.random.choice(pos_indices.shape[0], sample_per_class, replace=True)\n",
        "        choice_anchor = pos_indices[choice_anchor]\n",
        "\n",
        "        choice_pos = np.random.choice(pos_indices.shape[0], sample_per_class, replace=True)\n",
        "        choice_pos = pos_indices[choice_pos]\n",
        "\n",
        "        choice_neg = np.random.choice(neg_indices.shape[0], sample_per_class, replace=True)\n",
        "        choice_neg = neg_indices[choice_neg]\n",
        "\n",
        "        sub_x_anc = dataset[choice_anchor]\n",
        "\n",
        "        sub_x_pos = dataset[choice_pos]\n",
        "\n",
        "        sub_x_neg = dataset[choice_neg]\n",
        "\n",
        "\n",
        "        if(x is None):\n",
        "            x = [(sub_x_anc), (sub_x_pos), (sub_x_neg)]\n",
        "            y = [label[choice_anchor], label[choice_pos], label[choice_neg]]\n",
        "        else:\n",
        "            x[0] = np.vstack((x[0], (sub_x_anc)))\n",
        "            x[1] = np.vstack((x[1], (sub_x_pos)))\n",
        "            x[2] = np.vstack((x[2], (sub_x_neg)))\n",
        "\n",
        "            y[0] = np.hstack((y[0].flatten(), label[choice_anchor].flatten()))\n",
        "            y[1] = np.hstack((y[1].flatten(), label[choice_pos].flatten()))\n",
        "            y[2] = np.hstack((y[2].flatten(), label[choice_neg].flatten()))\n",
        "            # y[0] = np.vstack((y[0].flatten(), label[choice_anchor].flatten()))\n",
        "            # y[1] = np.vstack((y[1].flatten(), label[choice_pos].flatten()))\n",
        "            # y[2] = np.vstack((y[2].flatten(), label[choice_neg].flatten()))\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmZi1nkYejnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, train_y = generate_triplets(x_train_master, y_train_master)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ2lU_y1ejrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_train_master)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqzqHdW2ejxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_x),train_x[0].shape, len(train_y))\n",
        "      \n",
        "print(\"Anchor labels:{}\".format(train_y[0]))\n",
        "print(\"Positive labels:{}\".format(train_y[1]))\n",
        "print(\"Negative labels:{}\".format(train_y[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkAA0Qk_ej2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_data(data, n):\n",
        "    n = min(len(data[0]), n)\n",
        "    random_choices = np.random.choice(len(data[0]),n, replace=False)\n",
        "    fig, ax = plt.subplots(n, 3,figsize=(10,40))\n",
        "    anc, pos, neg = data\n",
        "    for i,ch in enumerate(random_choices):\n",
        "        ax[i, 0].imshow(np.squeeze(anc[ch] ))\n",
        "        ax[i, 1].imshow(np.squeeze(pos[ch] ))\n",
        "        ax[i, 2].imshow(np.squeeze(neg[ch] ))\n",
        "\n",
        "\n",
        "        ax[i, 0].set_axis_off()\n",
        "        ax[i, 1].set_axis_off()\n",
        "        ax[i, 2].set_axis_off()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbfwUhniej7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_data(train_x, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGPcD7t1ekAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num=300\n",
        "num_train_per_class=int(num*.80)\n",
        "num_test_per_class=int(num*.20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7RpJRJTekIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, train_y = generate_triplets(x_train_master, y_train_master, num_train_per_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUzCEb2sekX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x, test_y = generate_triplets(x_test_master, y_test_master,num_test_per_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmTbGy3ekGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "aca0fb0e-ee72-4c5a-c129-fabb3bb38cfd"
      },
      "source": [
        "print(\"Length of generated triplet for Train Data:{},{}\".format(len(train_x),train_x[0].shape))\n",
        "print(\"Length of generated triplet for Test Data:\", len(test_x),test_x[0].shape)\n",
        "print(\"Length of generated triplet for Train Label:{},{}\".format(len(train_y),train_y[0].shape))\n",
        "print(\"Length of generated triplet for Test Label:\", len(test_y),test_y[0].shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of generated triplet for Train Data:3,(11520, 224, 224, 1)\n",
            "Length of generated triplet for Test Data: 3 (2880, 224, 224, 1)\n",
            "Length of generated triplet for Train Label:3,(11520,)\n",
            "Length of generated triplet for Test Label: 3 (2880,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UUZUyl_ekE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(inputs, dist='euclidean', margin='maxplus'):\n",
        "    print(\"loss calculation\")\n",
        "    alpha=0.4\n",
        "    anchor, positive, negative = inputs\n",
        "    positive_distance = K.square(anchor - positive)\n",
        "    negative_distance = K.square(anchor - negative)\n",
        "    if dist == 'euclidean':\n",
        "        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n",
        "        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n",
        "    elif dist == 'sqeuclidean':\n",
        "        positive_distance = K.sum(positive_distance, axis=-1, keepdims=True)\n",
        "        negative_distance = K.sum(negative_distance, axis=-1, keepdims=True)\n",
        "    loss = positive_distance - negative_distance\n",
        "    if margin == 'maxplus':\n",
        "        loss = K.maximum(0.0, alpha + loss)\n",
        "    elif margin == 'softplus':\n",
        "        loss = K.log(1 + K.exp(loss))\n",
        "    return K.mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Ic2-xPej-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def our_model(in_dims):\n",
        "   model = Sequential()\n",
        "   model.add(Conv2D(64, kernel_size=5, input_shape=(in_dims[0],in_dims[1],in_dims[2],), activation=\"relu\"))\n",
        "   model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  #  model.add(Dropout(0.25))\n",
        "   model.add(Conv2D(64, kernel_size=5, activation=\"relu\"))\n",
        "   model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "   model.add(Conv2D(128, kernel_size=5, activation=\"relu\"))\n",
        "   model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "   model.add(Conv2D(64, kernel_size=5, activation=\"relu\"))\n",
        "   model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "   model.add(Dropout(0.25)) \n",
        "   return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd5kZK6ISEH9",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYKWIWKLej5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "def create_base_network(in_dims, embedding_dim):\n",
        "\n",
        "    _input = Input(shape=in_dims)\n",
        "    our_model_object=our_model(in_dims)\n",
        "    output_ourModel = our_model_object(_input)\n",
        "\n",
        "    x = Flatten()(output_ourModel)\n",
        "    x = Dense(embedding_dim * 4,activation=\"relu\")(x)\n",
        "    x = Dense(embedding_dim * 2, activation='relu')(x)\n",
        "    x = Dense(embedding_dim)(x)\n",
        "    \n",
        "    return Model(_input, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOOxoPQjej1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network_model(input_shape, triplet_margin=.3, embedding_dim=50):\n",
        "\n",
        "  anchor_input = Input((dim_x,dim_y,1, ), name='anchor_input')\n",
        "  positive_input = Input((dim_x,dim_y,1, ), name='positive_input')\n",
        "  negative_input = Input((dim_x,dim_y,1, ), name='negative_input')\n",
        "\n",
        "  Shared_DNN=create_base_network(input_shape, embedding_dim)\n",
        "  \n",
        "  encoded_anchor = Shared_DNN(anchor_input)\n",
        "  encoded_positive = Shared_DNN(positive_input)\n",
        "  encoded_negative = Shared_DNN(negative_input)\n",
        "\n",
        "  inputs=[anchor_input, positive_input, negative_input]\n",
        "  outputs=[encoded_anchor, encoded_positive, encoded_negative]\n",
        "\n",
        "  triplet=Model(inputs=inputs, outputs=outputs)\n",
        "  triplet.add_loss((triplet_loss(outputs, dist='euclidean', margin='maxplus'))) \n",
        "\n",
        "  return Shared_DNN, triplet\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMwp_D0Vejvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55a26542-9701-448e-ec78-e365fb236e40"
      },
      "source": [
        "#print(dim_x)\n",
        "Shared_DNN, triplet= network_model((dim_x,dim_y,1), triplet_margin=.3, embedding_dim=150)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss calculation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC73qpFkfAvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "3445e273-0b9a-43b7-d6e2-538c1295477d"
      },
      "source": [
        "#model.compile(loss=keras.losses.categorical_crossentropy, optimizer=optimizers.RMSprop(),metrics=['accuracy'])\n",
        "triplet.compile(loss=None, optimizer=optimizers.RMSprop(lr=0.0001))\n",
        "triplet.summary()\n",
        "# Adam(0.0001)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "anchor_input (InputLayer)       (None, 224, 224, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positive_input (InputLayer)     (None, 224, 224, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "negative_input (InputLayer)     (None, 224, 224, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 150)          4579970     anchor_input[0][0]               \n",
            "                                                                 positive_input[0][0]             \n",
            "                                                                 negative_input[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 4,579,970\n",
            "Trainable params: 4,579,970\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output model_3 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to model_3.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OzuXFtGfFpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c243973b-a27c-420e-cc8e-a6a17aee2719"
      },
      "source": [
        "## Training\n",
        "n_epochs=50\n",
        "#my_model.fit(features_train, labels_train, epochs=100, batch_size=16, callbacks=[tensorboard,earlystopping], validation_data=(features_test, labels_test))\n",
        "history = triplet.fit(train_x, shuffle=True, batch_size=32, validation_split=.1, epochs=n_epochs)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10368 samples, validate on 1152 samples\n",
            "Epoch 1/50\n",
            "10368/10368 [==============================] - 40s 4ms/step - loss: 0.3041 - val_loss: 0.1060\n",
            "Epoch 2/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.1055 - val_loss: 0.0765\n",
            "Epoch 3/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0903 - val_loss: 0.0889\n",
            "Epoch 4/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0826 - val_loss: 0.0612\n",
            "Epoch 5/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0712 - val_loss: 0.0584\n",
            "Epoch 6/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0684 - val_loss: 0.0601\n",
            "Epoch 7/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0657 - val_loss: 0.0609\n",
            "Epoch 8/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0608 - val_loss: 0.0644\n",
            "Epoch 9/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0564 - val_loss: 0.0579\n",
            "Epoch 10/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0537 - val_loss: 0.0598\n",
            "Epoch 11/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0515 - val_loss: 0.0568\n",
            "Epoch 12/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0499 - val_loss: 0.0577\n",
            "Epoch 13/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0476 - val_loss: 0.0553\n",
            "Epoch 14/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0436 - val_loss: 0.0486\n",
            "Epoch 15/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0415 - val_loss: 0.0660\n",
            "Epoch 16/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0398 - val_loss: 0.0544\n",
            "Epoch 17/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0375 - val_loss: 0.0453\n",
            "Epoch 18/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0381 - val_loss: 0.0553\n",
            "Epoch 19/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0354 - val_loss: 0.0478\n",
            "Epoch 20/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0327 - val_loss: 0.0521\n",
            "Epoch 21/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0321 - val_loss: 0.0580\n",
            "Epoch 22/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0302 - val_loss: 0.0627\n",
            "Epoch 23/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0304 - val_loss: 0.0498\n",
            "Epoch 24/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0260 - val_loss: 0.0509\n",
            "Epoch 25/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0260 - val_loss: 0.0515\n",
            "Epoch 26/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0254 - val_loss: 0.0594\n",
            "Epoch 27/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0237 - val_loss: 0.0563\n",
            "Epoch 28/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0221 - val_loss: 0.0687\n",
            "Epoch 29/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0214 - val_loss: 0.0527\n",
            "Epoch 30/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0202 - val_loss: 0.0694\n",
            "Epoch 31/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0214 - val_loss: 0.0622\n",
            "Epoch 32/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0193 - val_loss: 0.0554\n",
            "Epoch 33/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0186 - val_loss: 0.0572\n",
            "Epoch 34/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0169 - val_loss: 0.0514\n",
            "Epoch 35/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0170 - val_loss: 0.0605\n",
            "Epoch 36/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0173 - val_loss: 0.0506\n",
            "Epoch 37/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0163 - val_loss: 0.0659\n",
            "Epoch 38/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0147 - val_loss: 0.0536\n",
            "Epoch 39/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0134 - val_loss: 0.0514\n",
            "Epoch 40/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0152 - val_loss: 0.0610\n",
            "Epoch 41/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0129 - val_loss: 0.0546\n",
            "Epoch 42/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0132 - val_loss: 0.0794\n",
            "Epoch 43/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0118 - val_loss: 0.0870\n",
            "Epoch 44/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0125 - val_loss: 0.0742\n",
            "Epoch 45/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0134 - val_loss: 0.0530\n",
            "Epoch 46/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0123 - val_loss: 0.0644\n",
            "Epoch 47/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0123 - val_loss: 0.0731\n",
            "Epoch 48/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0099 - val_loss: 0.0783\n",
            "Epoch 49/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0106 - val_loss: 0.0845\n",
            "Epoch 50/50\n",
            "10368/10368 [==============================] - 39s 4ms/step - loss: 0.0101 - val_loss: 0.0591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzA-yqTWLVQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "77cee600-d38c-4a3c-dd88-e48a12d46dec"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05SVngtuLkAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triplet.save(\"MITTripletLossAditi.h5\") #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xivf8rYAL3Jd",
        "colab_type": "text"
      },
      "source": [
        "**Get the Encoding/Embedding Value for Train data(Anchor, Positive)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEaPLmFgMEu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_anchor_embeds=Shared_DNN.predict(train_x[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoVjVFJAMFBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_positive_embeds=Shared_DNN.predict(train_x[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-wNxDNXMFPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_negative_embeds=Shared_DNN.predict(train_x[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adnXzRzyME-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5ddb8dfb-5426-460a-f35b-5ec697b40823"
      },
      "source": [
        "print(\"Shape of Embeddings for Train(Anchor) data:{}\".format(train_anchor_embeds.shape))\n",
        "print(\"Shape of Embeddings for Train(positive) data:{}\".format(train_positive_embeds.shape))\n",
        "print(\"Shape of Embeddings for Train(negative) data:{}\".format(train_negative_embeds.shape))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Embeddings for Train(Anchor) data:(11520, 150)\n",
            "Shape of Embeddings for Train(positive) data:(11520, 150)\n",
            "Shape of Embeddings for Train(negative) data:(11520, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buohn7IcMhnw",
        "colab_type": "text"
      },
      "source": [
        "**Get value of k templates for each label using trained data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyLFT5YUMhts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " train_data_v_stack=np.vstack((train_x[0], train_x[1], train_x[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C750M42dMh4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the embeddings of the images\n",
        "def get_image_embedding(test_model, input): \n",
        "  train_embeds = test_model.predict(input)\n",
        "  return train_embeds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZffMVJlZMh-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c10f17e-a8fd-4455-9fc5-bfa0cfd1d271"
      },
      "source": [
        "train_embeds=get_image_embedding(Shared_DNN, train_x[0])\n",
        "print(\"Train Embeddings shape:{}\".format(train_embeds.shape))\n",
        "#print(train_embeds[0], train_embeds[1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Embeddings shape:(11520, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM9KLVzxMhlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_v_stack = np.vstack((train_x[0], train_x[1], train_x[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sWBquiZMt1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label_v_stack = np.vstack((train_y[0], train_y[1], train_y[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYgo8BzEMuFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b516bacc-577b-4b2c-8d21-3c49d8339731"
      },
      "source": [
        "print(\"Shape of vertical_stacked train data: {}\".format(train_data_v_stack.shape))\n",
        "print(\"Shape of vertical_stacked train label in form of [[],[],[]]: {}\".format(train_label_v_stack.shape))\n",
        "print(\"Labels of Anchor Image:{}\".format(train_label_v_stack[0]))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of vertical_stacked train data: (34560, 224, 224, 1)\n",
            "Shape of vertical_stacked train label in form of [[],[],[]]: (3, 11520)\n",
            "Labels of Anchor Image:[ 0  0  0 ... 47 47 47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRSyshZgMy5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28f6f164-5cab-4863-e7ef-04cb39d492bd"
      },
      "source": [
        "print(train_y[1].shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11520,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfprTL3vMzKE",
        "colab_type": "text"
      },
      "source": [
        "### **`Calculating Threshold using Trained Data`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMA15tpMMzXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8045c40-be93-458e-c0bc-79196146db52"
      },
      "source": [
        "map_threshold_calc={}\n",
        "for unique_label in unique_labels:\n",
        "  print(unique_label)\n",
        "  target_label=np.argwhere(train_label_v_stack[1]==unique_label)\n",
        "  # List of list format,So need to change into single list using chain\n",
        "  target_label = list(chain.from_iterable(target_label)) \n",
        "  start_index=target_label[0]\n",
        "  end_index=target_label[-1]\n",
        "  # Data stored of Positive Image value for threshold calculation\n",
        "  data_per_label_threshold=train_positive_embeds[start_index:end_index+1]\n",
        "  map_threshold_calc[unique_label]=data_per_label_threshold\n",
        "  print(map_threshold_calc[unique_label].shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(240, 150)\n",
            "1\n",
            "(240, 150)\n",
            "2\n",
            "(240, 150)\n",
            "3\n",
            "(240, 150)\n",
            "4\n",
            "(240, 150)\n",
            "5\n",
            "(240, 150)\n",
            "6\n",
            "(240, 150)\n",
            "7\n",
            "(240, 150)\n",
            "8\n",
            "(240, 150)\n",
            "9\n",
            "(240, 150)\n",
            "10\n",
            "(240, 150)\n",
            "11\n",
            "(240, 150)\n",
            "12\n",
            "(240, 150)\n",
            "13\n",
            "(240, 150)\n",
            "14\n",
            "(240, 150)\n",
            "15\n",
            "(240, 150)\n",
            "16\n",
            "(240, 150)\n",
            "17\n",
            "(240, 150)\n",
            "18\n",
            "(240, 150)\n",
            "19\n",
            "(240, 150)\n",
            "20\n",
            "(240, 150)\n",
            "21\n",
            "(240, 150)\n",
            "22\n",
            "(240, 150)\n",
            "23\n",
            "(240, 150)\n",
            "24\n",
            "(240, 150)\n",
            "25\n",
            "(240, 150)\n",
            "26\n",
            "(240, 150)\n",
            "27\n",
            "(240, 150)\n",
            "28\n",
            "(240, 150)\n",
            "29\n",
            "(240, 150)\n",
            "30\n",
            "(240, 150)\n",
            "31\n",
            "(240, 150)\n",
            "32\n",
            "(240, 150)\n",
            "33\n",
            "(240, 150)\n",
            "34\n",
            "(240, 150)\n",
            "35\n",
            "(240, 150)\n",
            "36\n",
            "(240, 150)\n",
            "37\n",
            "(240, 150)\n",
            "38\n",
            "(240, 150)\n",
            "39\n",
            "(240, 150)\n",
            "40\n",
            "(240, 150)\n",
            "41\n",
            "(240, 150)\n",
            "42\n",
            "(240, 150)\n",
            "43\n",
            "(240, 150)\n",
            "44\n",
            "(240, 150)\n",
            "45\n",
            "(240, 150)\n",
            "46\n",
            "(240, 150)\n",
            "47\n",
            "(240, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8dxOTs9ND4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial import distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFmBvBHqNEIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "842ebc7d-8fab-44ad-c17d-2613e6b08364"
      },
      "source": [
        "map_threshold_value={}\n",
        "for key in map_threshold_calc.keys():\n",
        "  data=map_threshold_calc[key]\n",
        "  # print(data)\n",
        "  dists = distance.cdist(data, data, 'euclidean')\n",
        "  print(dists.shape)\n",
        "  average_calc=[]\n",
        "  for dist in dists:\n",
        "    mean=np.mean(dist)\n",
        "    standard_deviation=np.std(dist)\n",
        "    dist_mean=abs(dist-mean)\n",
        "    soln_array=dist_mean<standard_deviation*1.75\n",
        "    soln_array1=dist[soln_array]\n",
        "    maximum=max(soln_array1)\n",
        "    average_calc.append(maximum)\n",
        "  threshold_for_label = sum(average_calc)/len(average_calc)\n",
        "  print(\"Threshold for Label {}:{}\".format(key, threshold_for_label))\n",
        "  map_threshold_value[key]=threshold_for_label"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240, 240)\n",
            "Threshold for Label 0:3.4055262987157926\n",
            "(240, 240)\n",
            "Threshold for Label 1:3.7886800980777613\n",
            "(240, 240)\n",
            "Threshold for Label 2:3.9427251042402554\n",
            "(240, 240)\n",
            "Threshold for Label 3:2.806722945863883\n",
            "(240, 240)\n",
            "Threshold for Label 4:4.8137845537627735\n",
            "(240, 240)\n",
            "Threshold for Label 5:3.479185018850814\n",
            "(240, 240)\n",
            "Threshold for Label 6:4.068206623051412\n",
            "(240, 240)\n",
            "Threshold for Label 7:3.7432773588202695\n",
            "(240, 240)\n",
            "Threshold for Label 8:4.221948184221173\n",
            "(240, 240)\n",
            "Threshold for Label 9:3.8520249001799325\n",
            "(240, 240)\n",
            "Threshold for Label 10:4.076116847955737\n",
            "(240, 240)\n",
            "Threshold for Label 11:4.269184502625465\n",
            "(240, 240)\n",
            "Threshold for Label 12:4.495791531188194\n",
            "(240, 240)\n",
            "Threshold for Label 13:5.253499933800741\n",
            "(240, 240)\n",
            "Threshold for Label 14:3.779839189795112\n",
            "(240, 240)\n",
            "Threshold for Label 15:3.4599223297145767\n",
            "(240, 240)\n",
            "Threshold for Label 16:6.92097492373303\n",
            "(240, 240)\n",
            "Threshold for Label 17:4.254757971062613\n",
            "(240, 240)\n",
            "Threshold for Label 18:3.994963788516818\n",
            "(240, 240)\n",
            "Threshold for Label 19:2.5784330141117895\n",
            "(240, 240)\n",
            "Threshold for Label 20:2.0645921096070645\n",
            "(240, 240)\n",
            "Threshold for Label 21:3.6500890401833805\n",
            "(240, 240)\n",
            "Threshold for Label 22:3.411410531768442\n",
            "(240, 240)\n",
            "Threshold for Label 23:4.730586323460366\n",
            "(240, 240)\n",
            "Threshold for Label 24:4.358168004164207\n",
            "(240, 240)\n",
            "Threshold for Label 25:3.619093745350996\n",
            "(240, 240)\n",
            "Threshold for Label 26:6.306849014665057\n",
            "(240, 240)\n",
            "Threshold for Label 27:3.866441515069431\n",
            "(240, 240)\n",
            "Threshold for Label 28:4.896694800092695\n",
            "(240, 240)\n",
            "Threshold for Label 29:5.60691881097678\n",
            "(240, 240)\n",
            "Threshold for Label 30:4.959350894508278\n",
            "(240, 240)\n",
            "Threshold for Label 31:4.849325202841579\n",
            "(240, 240)\n",
            "Threshold for Label 32:4.919152930430299\n",
            "(240, 240)\n",
            "Threshold for Label 33:4.890590001788751\n",
            "(240, 240)\n",
            "Threshold for Label 34:4.894745430421229\n",
            "(240, 240)\n",
            "Threshold for Label 35:4.587946699092354\n",
            "(240, 240)\n",
            "Threshold for Label 36:4.272063887851155\n",
            "(240, 240)\n",
            "Threshold for Label 37:4.475478645674135\n",
            "(240, 240)\n",
            "Threshold for Label 38:3.281473903522759\n",
            "(240, 240)\n",
            "Threshold for Label 39:4.483510192186021\n",
            "(240, 240)\n",
            "Threshold for Label 40:4.621136818331099\n",
            "(240, 240)\n",
            "Threshold for Label 41:5.076353417196153\n",
            "(240, 240)\n",
            "Threshold for Label 42:4.341784166161817\n",
            "(240, 240)\n",
            "Threshold for Label 43:4.582509377384861\n",
            "(240, 240)\n",
            "Threshold for Label 44:6.537332614259403\n",
            "(240, 240)\n",
            "Threshold for Label 45:5.9369375556350885\n",
            "(240, 240)\n",
            "Threshold for Label 46:6.740322621482753\n",
            "(240, 240)\n",
            "Threshold for Label 47:3.6366263472972666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6G22DYrNET2",
        "colab_type": "text"
      },
      "source": [
        "**Testing & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1ZLv5flNEd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4a86b691-daf8-48f5-a3c9-e66a7ae0afc2"
      },
      "source": [
        "print(\"What is your claimed identity?\")\n",
        "claimed_label=input()\n",
        "print(claimed_label)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is your claimed identity?\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eruV2xWsNEEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_k_template_values(label):\n",
        "  label=int(label)\n",
        "  target_label=np.argwhere(train_label_v_stack[0]==label)\n",
        "  # List of list format.So need to change into single list using chain\n",
        "  target_label = list(chain.from_iterable(target_label)) \n",
        "  #print(target_label)\n",
        "\n",
        "  k_template_value=[]\n",
        "  for value in target_label:\n",
        "    k_template_value.append(train_embeds[value])\n",
        "  #print(\"K templates, Value of k:{}, template shape:{}\".format(len(k_template_value), len(k_template_value[0])))\n",
        "  return k_template_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agzmSzI6NApX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k_template_value=get_k_template_values(claimed_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9I4vIabNTLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ffecbbdd-9b4b-4392-ddb7-c428b38a6a9e"
      },
      "source": [
        "test_data_v_stack=np.vstack((test_x[0], test_x[1], test_x[2]))\n",
        "test_label_v_stack=np.vstack((test_y[0], test_y[1], test_y[2]))\n",
        "print(\"Shape of vertical_stacked test data: {}\".format(test_data_v_stack.shape))\n",
        "print(\"Shape of vertical_stacked test label in form of [[],[],[]]: {}\".format(test_label_v_stack.shape))\n",
        "print(\"Labels of Image to test:{}\".format(test_label_v_stack[0]))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of vertical_stacked test data: (8640, 224, 224, 1)\n",
            "Shape of vertical_stacked test label in form of [[],[],[]]: (3, 2880)\n",
            "Labels of Image to test:[ 0  0  0 ... 47 47 47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRF_ex2tNVlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "691add7b-a41a-4c9c-c6a2-5f29a353c226"
      },
      "source": [
        "print(\"Select any label!\")\n",
        "print(set(test_label_v_stack[0]))\n",
        "real_identity = input()\n",
        "print(\"Input Value:\", real_identity)\n",
        "\n",
        "\n",
        "# claimed_identity = 2"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select any label!\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47}\n",
            "20\n",
            "Input Value: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD9WACGtNYCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8802f988-e6c4-4f7a-a178-dfdd185dc96b"
      },
      "source": [
        "# test_label=np.argwhere(test_label_v_stack[0]==2)\n",
        "test_label=np.argwhere(test_label_v_stack[0]==int(real_identity))\n",
        "test_label = list(chain.from_iterable(test_label)) \n",
        "# Multiple values of the same label in test_data, so we will select any random one\n",
        "print(test_label)\n",
        "# print(random_test_label)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn_JJeSRNb7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13e92b1c-2c88-4fd1-c375-aad2a196e6b3"
      },
      "source": [
        "# test_segment=None\n",
        "random_test_label=test_label[0]\n",
        "random_test_data=(test_data_v_stack[random_test_label]).reshape(1,224,224,1)\n",
        "print(\"Corresponding image shape:\", random_test_data.shape)\n",
        "test_embeds = Shared_DNN.predict(random_test_data)\n",
        "print(\"Shape of test template:{}\".format(test_embeds.shape))\n",
        "test_segment=test_embeds"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corresponding image shape: (1, 224, 224, 1)\n",
            "Shape of test template:(1, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt37AEJ_Nd3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def similar_score(test_template, stored_templates):\n",
        "  dists = distance.cdist(test_template, stored_templates, 'euclidean')\n",
        "  soln=min(dists[0])\n",
        "  return soln"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQSMQ7y8Ng0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab535da7-a7dc-4344-f326-2032e7ad7005"
      },
      "source": [
        "score=similar_score(test_segment, k_template_value)\n",
        "print(score)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.406552793981744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64PcHWhrNjiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb565402-a1df-4d47-8e47-de63b4f11303"
      },
      "source": [
        "threshold=map_threshold_value[int(claimed_label)]\n",
        "print(threshold)\n",
        "if score>threshold:\n",
        "  print(\"You are not authenticated with dissimarity score:{}\".format(score))\n",
        "else:\n",
        "  print(\"Authentication Successful! with dissimarity score:{}\".format(score))\n",
        "    "
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.4055262987157926\n",
            "You are not authenticated with dissimarity score:7.406552793981744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3EV5jfDNnnw",
        "colab_type": "text"
      },
      "source": [
        "### Authentication Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzVJGLfDNswt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def authentication(test_segment,claimed_label):\n",
        "  k_template_value=get_k_template_values(claimed_label)\n",
        "  test_embeds = Shared_DNN.predict(test_segment)\n",
        "  score=similar_score(test_embeds, k_template_value)\n",
        "  threshold=map_threshold_value[int(claimed_label)]\n",
        "  #print(threshold)\n",
        "  if score>threshold:\n",
        "    #print(\"You are not authenticated with dissimarity score:{}\".format(score))\n",
        "    return 'false'\n",
        "  else:\n",
        "    #print(\"Authentication Successful! with dissimarity score:{}\".format(score))\n",
        "    return 'true'\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgPXobXWNvLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb80d87f-61b9-475b-a1e9-89dd733267ce"
      },
      "source": [
        "test_segment=test_x[0][0].reshape(1,224,224,1)\n",
        "test_segment.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSU3-E66NxXA",
        "colab_type": "text"
      },
      "source": [
        "Check From here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9S10-LbN5UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_test_embeds=Shared_DNN.predict(test_x[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxm6qTtwN5hG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53d23f1d-315c-4823-8803-f79b89a05962"
      },
      "source": [
        "test_x[0][0].shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHkq9UsGN_i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_pos=0\n",
        "f_neg=0\n",
        "def countMetricsTruePositives():\n",
        "  true_positives=0\n",
        "  total=len(all_test_embeds)\n",
        "  for i in range(len(all_test_embeds)):\n",
        "    test_embed=all_test_embeds[i]\n",
        "    claimed_label=test_y[0][i]\n",
        "    test_segment=test_x[0][i].reshape(1,224,224,1)\n",
        "    response=authentication(test_segment,claimed_label)\n",
        "    if response == \"true\":\n",
        "      true_positives=true_positives+1\n",
        "  t_pos=true_positives\n",
        "  print(\"True Positives:\" ,true_positives)\n",
        "  f_neg=total-true_positives\n",
        "  print(\"False Negatives:\" ,f_neg)\n",
        "  return t_pos,f_neg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCGdVM6cOB7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4d6033d0-031c-4c8e-c78c-9138edddc166"
      },
      "source": [
        "t_pos,f_neg=countMetricsTruePositives()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 2877\n",
            "False Negatives: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvR_SUZsOEB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3930469f-e731-4517-e8d0-80ddc4819ddf"
      },
      "source": [
        "t_pos"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2877"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiuIpUvfOEuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "t_neg=0\n",
        "f_pos=0\n",
        "def countMetricsTrueNegatives():\n",
        "  true_negatives=0\n",
        "  total=len(all_test_embeds)\n",
        "  for i in range(len(all_test_embeds)):\n",
        "    test_embed=all_test_embeds[i]\n",
        "    if i == 0:\n",
        "      claimed_label=test_y[0][:1]\n",
        "    elif(i == len(all_test_embeds)-1):\n",
        "      claimed_label=test_y[0][0]\n",
        "    else:\n",
        "      claimed_label=test_y[0][i+1]\n",
        "    test_segment=test_x[0][i].reshape(1,224,224,1)\n",
        "    response=authentication(test_segment,claimed_label)\n",
        "    if response == \"true\":\n",
        "      true_negatives=true_negatives+1\n",
        "  t_neg=true_negatives\n",
        "  print(\"True Negatives:\" ,t_neg)\n",
        "  f_pos=total-true_negatives\n",
        "  print(\"False Positives:\" ,f_pos)\n",
        "  return t_neg,f_pos\n",
        "\n",
        "\n",
        "# t_neg1=0\n",
        "# f_pos1=0\n",
        "# def countMetricsTrueNegatives():\n",
        "#   true_negatives=0\n",
        "#   total=len(all_test_embeds)\n",
        " \n",
        "#   for i in range(len(all_test_embeds)):\n",
        "#     print(\"i value\",i)\n",
        "#     test_segment=test_x[0][i].reshape(1,224,224,1)\n",
        "#     test_embed=all_test_embeds[i]\n",
        "#     for j in range(len(test_y[0])):\n",
        "#       if i == j:\n",
        "#         continue\n",
        "#       else:\n",
        "#         print(\"j value\", j)\n",
        "#         claimed_label=test_y[0][j]\n",
        "#         response=authentication(test_segment,claimed_label)\n",
        "#         if response == \"true\":\n",
        "#           true_negatives=true_negatives+1\n",
        "#   t_neg=true_negatives\n",
        "#   print(\"True Negatives:\" ,t_neg)\n",
        "#   f_pos=total-true_negatives\n",
        "#   print(\"False Positives:\" ,f_pos)\n",
        "#   return t_neg,f_pos\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnLfuQNWOHJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e9e7de2-04e7-4286-e4b1-bcfa2cca91e0"
      },
      "source": [
        "t_neg,f_pos=countMetricsTrueNegatives()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Negatives: 2841\n",
            "False Positives: 39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdnNVMDOJH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eac2e3fe-0c4a-4455-912b-c2f5fefbaa03"
      },
      "source": [
        "#TP+TN/TP+TN+FN x 100%\n",
        "total_cases=t_pos+f_neg+t_neg+f_pos\n",
        "#print(total_cases)\n",
        "numerator=t_pos+t_neg\n",
        "accuracy=numerator/total_cases\n",
        "accuracy=accuracy*100\n",
        "print(\"Accuracy is: {}%\".format(accuracy))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 99.27083333333333%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEInIq0JOLNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}